{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score,roc_auc_score,accuracy_score,confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import pickle\n",
    "import warnings\n",
    "from optuna import Trial\n",
    "import collections\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_training(adataPath, hvgs):\n",
    "    # read data\n",
    "    adata = sc.read_10x_mtx(adataPath,var_names= 'gene_symbols',cache = False)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    # Filter HVGs --> Select top N highly variable genes that will serve as features to the machine learning models  \n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes = hvgs)\n",
    "    highly_variable_genes = adata.var[\"highly_variable\"]\n",
    "    highly_variable_genes_names = adata.var_names[adata.var['highly_variable']].to_list()\n",
    "    adata = adata[:, highly_variable_genes]\n",
    "    # Scale\n",
    "    sc.pp.scale(adata, max_value=10)\n",
    "    X_df = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var_names)\n",
    "    print(type(X_df), X_df.shape)\n",
    "    return X_df, highly_variable_genes_names\n",
    "\n",
    "root_df, highly_variable_genes  = preprocessing_training(adataPath = \"/public/home/lidongwei/work/scRNA_scATAC/part_sc_reference_atlas/data/merge_data/matrix_info\",\n",
    "                                    hvgs = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = pd.read_csv(\"/public/home/lidongwei/work/scRNA_scATAC/part_sc_reference_atlas/data/merge_data/wxy_wjw_lq_merge_meta_231121.csv\",index_col=0)\n",
    "\n",
    "root_df = root_df.sort_index()\n",
    "cell_type = cell_type.sort_index()\n",
    "\n",
    "cell_type_label = cell_type['cell_type'].values\n",
    "print(type(cell_type_label), cell_type_label.shape)\n",
    "print('List of unique labels we wish to transfer: {}'.format(np.unique(cell_type_label)))\n",
    "print(collections.Counter(cell_type['cell_type']))\n",
    "\n",
    "unique_labels, label_counts = np.unique(cell_type_label, return_counts=True)\n",
    "\n",
    "plt.bar(unique_labels, label_counts/len(cell_type_label))\n",
    "plt.title(\"Proportion of Labels\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def downsample_data(count, raw_label, threshold):\n",
    "    label = pd.DataFrame(raw_label)\n",
    "    data = pd.concat([count, label], axis=1)\n",
    "\n",
    "    sample_counts = label['cell_type'].value_counts().to_dict()\n",
    "\n",
    "    downsampled_data = pd.DataFrame()  \n",
    "\n",
    "    for label, count in sample_counts.items():\n",
    "        if count > threshold:\n",
    "            samples = data[data['cell_type'] == label].sample(n=threshold, random_state=1)\n",
    "            downsampled_data = pd.concat([downsampled_data, samples])  \n",
    "        else:\n",
    "            samples = data[data['cell_type'] == label]\n",
    "            downsampled_data = pd.concat([downsampled_data, samples])\n",
    "\n",
    "    features = downsampled_data.drop('cell_type', axis=1)  \n",
    "    labels = downsampled_data['cell_type']  \n",
    "\n",
    "    return features, labels\n",
    "\n",
    "root_df_down,cell_type_label_down = downsample_data(root_df,cell_type['cell_type'],5000)\n",
    "\n",
    "print(collections.Counter(cell_type_label_down))\n",
    "print(root_df_down.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pro(x,y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2,random_state=33,stratify=y)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# Split the training dataset into train and test sets \n",
    "X_train, X_test, y_train, y_test = data_pro(root_df_down,cell_type_label_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective(object):\n",
    "    def __init__(self, x_calib, y_calib, cv_folds,use_thread_count,use_task,use_device, scoring_type):\n",
    "        self.x_calib = x_calib\n",
    "        self.y_calib = y_calib\n",
    "        self.use_thread_count = use_thread_count\n",
    "        self.use_task = use_task\n",
    "        self.use_device = use_device\n",
    "        self.scoring_type = scoring_type\n",
    "        self.cv_folds = cv_folds\n",
    " \n",
    "    def __call__(self, trial):\n",
    "         \n",
    "        params = {'iterations':trial.suggest_int(\"iterations\", 100, 1000),\n",
    "              'loss_function':'MultiClass',\n",
    "              'boosting_type':'Plain',\n",
    "              'custom_metric':'Accuracy',\n",
    "              'eval_metric':'TotalF1',\n",
    "              'leaf_estimation_method':'Newton',\n",
    "              'bootstrap_type': 'Bernoulli',\n",
    "              'learning_rate' : trial.suggest_uniform('learning_rate',1e-3, 1),\n",
    "              'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "              'random_strength': trial.suggest_uniform('random_strength', 1e-3, 10.0),\n",
    "              'depth': trial.suggest_int('depth',4,13),\n",
    "              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,50),\n",
    "              'auto_class_weights':trial.suggest_categorical('auto_class_weights', [None,'Balanced'])\n",
    "               }\n",
    "    \n",
    "        if self.use_task == 'GPU':\n",
    "            classifier_obj = CatBoostClassifier(**params,task_type='GPU',thread_count=self.use_thread_count,\n",
    "                                                devices=self.use_device,verbose=False,allow_writing_files=False)\n",
    "        elif self.use_task == 'CPU':\n",
    "            classifier_obj = CatBoostClassifier(**params,task_type='CPU',thread_count=self.use_thread_count,\n",
    "                                                verbose=False,allow_writing_files=False) \n",
    "        score = cross_val_score(classifier_obj, self.x_calib, self.y_calib, \n",
    "                                cv=StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=1), \n",
    "                                scoring=self.scoring_type, n_jobs=self.use_thread_count)\n",
    "        mean_cv_score = score.mean()\n",
    "        \n",
    "        return mean_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_type =  'accuracy'\n",
    "optimizer_direction = 'maximize'\n",
    "cv_folds = 10\n",
    "number_of_random_points = 15 # defualt 10\n",
    "x_calib = X_train\n",
    "y_calib = y_train\n",
    "use_thread_count = 1\n",
    "use_task = 'GPU'\n",
    "use_device = '0:1'\n",
    "\n",
    "optuna_objective = Objective(x_calib, y_calib, cv_folds,use_thread_count,use_task,use_device, scoring_type)\n",
    " \n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def optimizer_optuna(n_trials,number_of_random_points,optimizer_direction,optuna_objective):\n",
    " \n",
    "    use_sampler = TPESampler(n_startup_trials=number_of_random_points)\n",
    "\n",
    "    study = optuna.create_study(sampler=use_sampler, direction=optimizer_direction)\n",
    "    study.optimize(optuna_objective,n_trials=n_trials, show_progress_bar = True,gc_after_trial=True)\n",
    " \n",
    "    print('best_params:',study.best_trial.params,\n",
    "              'best_score:',study.best_trial.values,\n",
    "              '\\n')\n",
    " \n",
    "    return study.best_trial.params, study.best_trial.values\n",
    " \n",
    "n_trials = 50\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',message='The objective has been evaluated at this point before trails')\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "best_params, best_score = optimizer_optuna(n_trials,number_of_random_points,optimizer_direction,optuna_objective)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CatBoostClassifier(**best_params,verbose=False,task_type='GPU') \n",
    "best_model.fit(X_train, y_train) \n",
    "\n",
    "pickle.dump(best_model, open(\"./results/root_catboost_best_model.pkl\", \"wb\"))\n",
    "\n",
    "#Print scores for Multiclass \n",
    "y_pred_1 = best_model.predict(X_test) \n",
    "y_prob_1 = best_model.predict_proba(X_test) \n",
    "f1 = f1_score(y_test, y_pred_1, average='macro')\n",
    "acc = accuracy_score(y_test, y_pred_1)\n",
    "print('f1 : ', f1)\n",
    "print('accuracy : ', acc)\n",
    "\n",
    "print(classification_report(y_test, y_pred_1, digits=3)) \n",
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_1)) \n",
    "print('Roc auc score : ', roc_auc_score(y_test, y_prob_1, multi_class='ovr'))\n",
    "\n",
    "skplt.metrics.plot_roc(y_test, y_prob_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = pickle.load(open(\"./results/root_catboost_best_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the reference genome most be MSU7 from Ensembl Plants (https://plants.ensembl.org)\n",
    "def preprocessing_test(adataPath, hvgs_names):\n",
    "    adata = sc.read_10x_mtx(adataPath,var_names= 'gene_symbols',cache = False)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    intersection_genes = list(set(adata.var_names) & set(hvgs_names))\n",
    "    adata = adata[:, intersection_genes]\n",
    "    # Scale\n",
    "    sc.pp.scale(adata, max_value=10)\n",
    "    X_df = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var_names)\n",
    "    complement_gene = list(set(hvgs_names) - set(X_df.columns))  \n",
    "    final_df = X_df.assign(**{col: 0 for col in complement_gene})\n",
    "    print(\"The count of model features is: \", len(hvgs_names))\n",
    "    print(\"The count of genes that intersect with the model features in the new dataset is: \", len(list(set(hvgs_names) & set(X_df.columns))))\n",
    "    print(type(final_df), final_df.shape)\n",
    "    return final_df\n",
    "\n",
    "test_root_df = preprocessing_test(adataPath = \"./test_data/filtered_feature_bc_matrix\",\n",
    "                             hvgs_names = highly_variable_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_catboost = best_model.predict(test_root_df) \n",
    "y_probas_catboost = best_model.predict_proba(test_root_df)\n",
    "result_df_catboost = pd.DataFrame({'Predicted_Label': predicted_labels_catboost.flatten()}, index=test_root_df.index)\n",
    "print(collections.Counter(result_df_catboost['Predicted_Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_catboost.to_csv('./results/Predicted_Label.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
